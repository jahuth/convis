

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>convis.base &mdash; convis 0.5.2.2 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="../../genindex.html"/>
        <link rel="search" title="Search" href="../../search.html"/>
    <link rel="top" title="convis 0.5.2.2 documentation" href="../../index.html"/>
        <link rel="up" title="Module code" href="../index.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> convis
          

          
          </a>

          
            
            
              <div class="version">
                0.5
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples.html#indices">Indices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../filters.html">Filters and Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pytorch_basics.html">PyTorch Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pytorch_basics.html#pytorch-extensions-in-convis">PyTorch Extensions in Convis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs.html">The API: Convis classes and modules</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">convis</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>convis.base</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for convis.base</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Convis base classes</span>
<span class="sd">----------------------</span>

<span class="sd">Convis extends PyTorch by adding some methods to `torch.nn.Module` and calling it a Layer.</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">.misc_utils</span> <span class="k">import</span> <span class="n">unique_list</span><span class="p">,</span> <span class="n">suppress</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">uuid</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="k">import</span> <span class="n">io</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">exceptions</span> <span class="k">import</span> <span class="ne">NotImplementedError</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="kn">from</span> <span class="nn">.variable_describe</span> <span class="k">import</span> <span class="n">describe</span><span class="p">,</span> <span class="n">describe_dict</span><span class="p">,</span> <span class="n">describe_html</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="k">import</span> <span class="n">variables</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="k">import</span> <span class="n">variable_describe</span>
<span class="kn">from</span> <span class="nn">.variables</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="k">import</span> <span class="n">utils</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="k">import</span> <span class="n">o</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="k">import</span> <span class="n">optimizer</span>
<span class="kn">from</span> <span class="nn">.o</span> <span class="k">import</span> <span class="n">O</span><span class="p">,</span> <span class="n">Ox</span><span class="p">,</span> <span class="n">save_name</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">OrderedDict</span>

<span class="c1"># ----</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="k">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">datetime</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">functools</span> <span class="k">import</span> <span class="n">reduce</span>
<span class="k">except</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="kn">from</span> <span class="nn">.variables</span> <span class="k">import</span> <span class="n">Variable</span><span class="p">,</span> <span class="n">State</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">,</span> <span class="n">as_parameter</span><span class="p">,</span> <span class="n">is_variable</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="k">import</span> <span class="n">deepcopy</span>

<span class="n">TIME_DIMENSION</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1">### Node and Model classes</span>

<span class="k">def</span> <span class="nf">len_parents</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="s1">&#39;parent&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">n</span><span class="o">.</span><span class="n">parent</span> <span class="o">!=</span> <span class="n">n</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">len_parents</span><span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">parent</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span>
    <span class="k">return</span> <span class="mi">0</span>

<div class="viewcode-block" id="Output"><a class="viewcode-back" href="../../docs.html#convis.base.Output">[docs]</a><span class="k">class</span> <span class="nc">Output</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This object provides a container for output numpy arrays which are labeled with theano variables.</span>

<span class="sd">        The outputs can be queried either by sorted order (like a simple list),</span>
<span class="sd">        by the theano variable which represents this output, the name of this variable</span>
<span class="sd">        or the full path of the variable.</span>
<span class="sd">        To make this meaningfull, provide a name to your output variables.</span>

<span class="sd">        In the case of name collisions, the behavior of OrderedDict will use the last variable added.</span>

<span class="sd">        The full path names of all variables are also added to this objects __dict__,</span>
<span class="sd">        allowing for tab completion.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">outs</span><span class="p">,</span><span class="n">keys</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            The full path names of all variables are also added to this objects __dict__,</span>
<span class="sd">            allowing for tab completion.</span>

<span class="sd">            By default returns a numpy array when used with square brackets, the </span>
<span class="sd">            Variable when accessed over `._outs[n]`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">({})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict_by_full_names</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">({})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict_by_short_names</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">({})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_outs</span> <span class="o">=</span> <span class="n">outs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keys</span> <span class="o">=</span> <span class="n">keys</span>
        <span class="k">if</span> <span class="n">keys</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span><span class="n">outs</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict_by_full_names</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">([(</span><span class="n">full_path</span><span class="p">(</span><span class="n">k</span><span class="p">),</span><span class="n">o</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">o</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span><span class="n">outs</span><span class="p">)])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict_by_short_names</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">([(</span><span class="n">save_name</span><span class="p">(</span><span class="n">get_convis_attribute</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="s1">&#39;name&#39;</span><span class="p">)),</span><span class="n">o</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">o</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span><span class="n">outs</span><span class="p">)</span> <span class="k">if</span> <span class="n">has_convis_attribute</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="s1">&#39;name&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="n">get_convis_attribute</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="s1">&#39;name&#39;</span><span class="p">))</span> <span class="ow">is</span> <span class="nb">str</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_out_dict</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_outs</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_outs</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">k</span><span class="p">],</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">array</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">variable</span><span class="o">.</span><span class="n">Variable</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">k</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">int</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_outs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">save_name</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict_by_short_names</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict_by_short_names</span><span class="p">[</span><span class="n">save_name</span><span class="p">(</span><span class="n">k</span><span class="p">)]</span>
            <span class="k">if</span> <span class="n">save_name</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict_by_full_names</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict_by_full_names</span><span class="p">[</span><span class="n">save_name</span><span class="p">(</span><span class="n">k</span><span class="p">)]</span>
        <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="o">!=</span> <span class="n">save_name</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="s1">&#39;Key not found: &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39; / &#39;</span><span class="o">+</span><span class="n">save_name</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
        <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="s1">&#39;Key not found: &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">))</span></div>

<span class="k">class</span> <span class="nc">_OptimizerSelection</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A single optimizer option that can be called to set this optimizer for the model.</span>
<span class="sd">        The doc string of the original optimizer is available by calling `help()` on this object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">opt</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_opt</span> <span class="o">=</span> <span class="n">opt</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_opt</span><span class="o">.</span><span class="vm">__doc__</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">set_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_opt</span><span class="p">,</span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">_OptimizerSelector</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Enables tab completion to set optimizers for a model.</span>
<span class="sd">        Includes all Optimizers found in `torch.nn.optim` and</span>
<span class="sd">        `convis.optimizer`.</span>

<span class="sd">        If optimizers are added to torch during runtime,</span>
<span class="sd">        you can call `._reload()` to add all available options.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">o</span><span class="p">))</span> <span class="ow">is</span> <span class="nb">type</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">o</span><span class="p">),</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">_OptimizerSelection</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">o</span><span class="p">)))</span>
        <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">optimizer</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">o</span><span class="p">))</span> <span class="ow">is</span> <span class="nb">type</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">o</span><span class="p">),</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">_OptimizerSelection</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span><span class="nb">getattr</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">o</span><span class="p">)))</span>
    <span class="k">def</span> <span class="nf">_reload</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">o</span><span class="p">))</span> <span class="ow">is</span> <span class="nb">type</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">o</span><span class="p">),</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">_OptimizerSelection</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">o</span><span class="p">)))</span>
        <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">optimizer</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">o</span><span class="p">))</span> <span class="ow">is</span> <span class="nb">type</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">o</span><span class="p">),</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">_OptimizerSelection</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span><span class="nb">getattr</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">o</span><span class="p">)))</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">types</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">list</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">types</span><span class="o">.</span><span class="n">GeneratorType</span><span class="p">)):</span>
            <span class="n">args</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
            <span class="n">args</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
        <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">opt</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">str</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">opt</span><span class="p">),</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">opt</span><span class="p">),</span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="prepare_input"><a class="viewcode-back" href="../../docs.html#convis.base.prepare_input">[docs]</a><span class="k">def</span> <span class="nf">prepare_input</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">volatile</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Utility function to broadcast input to 5 dimensions, make it a Tensor,</span>
<span class="sd">        wrap it in a Variable and optionally move it to the GPU.</span>

<span class="sd">        Short hand for::</span>

<span class="sd">            import torch</span>
<span class="sd">            a_var = torch.autograd.Variable(torch.Tensor(a[None,None,:,:,:]), requires_grad=True).cuda()</span>

<span class="sd">            from convis.base import prepare_input</span>
<span class="sd">            a_var = prepare_input(a, cuda=True, requires_grad=True)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="ow">is</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="s1">&#39;numpy&#39;</span><span class="p">):</span>
            <span class="c1"># its hopefully a torch.Tensor</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">volatile</span><span class="o">=</span><span class="n">volatile</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="n">requires_grad</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="n">volatile</span><span class="o">=</span><span class="n">volatile</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="n">requires_grad</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dims</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">dims</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">,:,:,:]</span>
        <span class="k">if</span> <span class="n">dims</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
                <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,:,:,:]</span>
    <span class="k">if</span> <span class="n">cuda</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">cuda</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span></div>

<div class="viewcode-block" id="shape"><a class="viewcode-back" href="../../docs.html#convis.base.shape">[docs]</a><span class="k">def</span> <span class="nf">shape</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the shape of a Tensor or Variable containing a Tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="s1">&#39;shape&#39;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="s1">&#39;data&#39;</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">data</span><span class="p">,</span><span class="s1">&#39;shape&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;No shape found for &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;!&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="Layer"><a class="viewcode-back" href="../../docs.html#convis.base.Layer">[docs]</a><span class="k">class</span> <span class="nc">Layer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base class for modules, layers and models.</span>

<span class="sd">        `convis.Layer` is a `torch.nn.Module` with some added functionality.</span>
<span class="sd">        </span>
<span class="sd">        In addition to a method `forward` that performs the computation, a</span>
<span class="sd">        `Layer` object also keeps track of a *state*, *parameter values* and </span>
<span class="sd">        an *optimizer*.</span>

<span class="sd">        The *state* is defined differently than the &quot;state&quot; of :class:`~torch.nn.Module`s:</span>
<span class="sd">        Since we process video in non-overlapping chunks, we need to save a bit of</span>
<span class="sd">        information between each chunk (the kind of information depends on the computation).</span>
<span class="sd">        This is the *state* of a Layer, which will change even if all parameters are held</span>
<span class="sd">        constant. (In contrast a `torch.nn.Module` state, eg. in `state_dict`, includes all parameters and buffers of the model)</span>
<span class="sd">        The values of *states* are only important between the processing of two consecutive</span>
<span class="sd">        inputs, so they usually do not have to be saved to disk, but they have to be stored</span>
<span class="sd">        and retrieved (using `get_state` and `set_state`) when moving non-continuously over the input.</span>

<span class="sd">        The *parameters* are variables of the model that have to be configured or fitted </span>
<span class="sd">        to make the model behave in the desired way. The values of these parameters </span>
<span class="sd">        define the response of the model to input and can be optimized to recreate a </span>
<span class="sd">        response observed in some data. </span>
<span class="sd">        These values can be saved to disc to preserve them.</span>

<span class="sd">        Layers can hold an internal *optimizer* that makes it easy to fit the parameters </span>
<span class="sd">        of a model to data.</span>

<span class="sd">        To create a Layer, create a subclass with an `__init__` and `forward` method::</span>

<span class="sd">            import convis</span>
<span class="sd">            import torch.nn.functional as F</span>

<span class="sd">            class Model(convis.Layer):</span>
<span class="sd">                def __init__(self):</span>
<span class="sd">                    super(Model, self).__init__()</span>
<span class="sd">                    self.conv1 = convis.filters.Conv3d(1, (20,1,1))</span>
<span class="sd">                    self.conv2 = convis.filters.Conv3d(1, (1,10,10))</span>
<span class="sd">                def forward(self, x):</span>
<span class="sd">                   x = F.relu(self.conv1(x))</span>
<span class="sd">                   return F.relu(self.conv2(x))</span>

<span class="sd">        Just as `Module`s, `Layer`s can include other `Layer`s or `Module`s (ie. its `sublayers`).</span>
<span class="sd">        `Variable`s, `Parameter`s and `State`s that are attributes of a Layer or</span>
<span class="sd">        its `sublayers` will be registered and can be collected according to their</span>
<span class="sd">        class.</span>
<span class="sd">        </span>
<span class="sd">        All registered Variables (including Parameters and States), will be moved to the</span>
<span class="sd">        corresponding device when calling `.cuda()` or `.cpu()`.</span>

<span class="sd">        In contrast to many methods of torch.Tensors, Layer methods are always</span>
<span class="sd">        in-place! Using `.cuda()` or `.float()` will return a reference to the </span>
<span class="sd">        original model and not a copy.</span>


<span class="sd">        Attributes</span>
<span class="sd">        ----------</span>

<span class="sd">        _use_cuda : bool</span>

<span class="sd">        .. py:attribute:: set_optimizer</span>

<span class="sd">            :class:`magic object &lt;convis.base._OptimizerSelector&gt;` that allows </span>
<span class="sd">            tab completion to select an optimizer. (see :ref:`example &lt;tab_completion_example&gt;`)</span>


<span class="sd">            The list of parameters as first argument can be omitted</span>
<span class="sd">            and will be filled with all parameters of the model by</span>
<span class="sd">            default. Other parameters are passed through to the optimizer.</span>

<span class="sd">        .. py:attribute:: user_parameteres</span>

<span class="sd">            A hierarchical, tab-completable list of all :class:`~torch.nn.Parameter`s/:class:`~convis.variables.Parameter`s</span>
<span class="sd">            /:class:`~convis.variables.VirtualParameter`s of the model that provide a `.set()` function for the user.</span>

<span class="sd">        .. py:attribute:: m</span>

<span class="sd">            A hierarchical, tab-completable list of all :class:`~torch.nn.Module`s/:class:`~convis.base.Layer`s of the model.</span>

<span class="sd">        .. py:attribute:: s</span>

<span class="sd">            A hierarchical, tab-completable list of all state variables of the model.</span>


<span class="sd">        Methods</span>
<span class="sd">        -------</span>

<span class="sd">        cuda(device=None)</span>
<span class="sd">            move the model to the gpu</span>
<span class="sd">        cpu()</span>
<span class="sd">            move the model to the cpu</span>

<span class="sd">        run(the_input, dt=None)</span>
<span class="sd">            execute the model, using chunk sizes of `dt`</span>

<span class="sd">        parse_config(conf)</span>

<span class="sd">        optimize(inp,outp,dt=None)</span>
<span class="sd">            use the selected optimizer to fit the model</span>
<span class="sd">            to return outp to the input inp.</span>
<span class="sd">            Accepts a chunk length `dt`</span>

<span class="sd">        register_state(name, value)</span>
<span class="sd">            registers an attribute name to be a state variable</span>
<span class="sd">        </span>
<span class="sd">        get_state()</span>
<span class="sd">            returns the current state of the model</span>
<span class="sd">            (recursively for all submodules)</span>

<span class="sd">        set_state(d)</span>
<span class="sd">            set all state parameters defined in dictionary `d`</span>
<span class="sd">            to the corresponding values.</span>

<span class="sd">        push_state()</span>
<span class="sd">            pushes the current state on a stack</span>

<span class="sd">        pop_state()</span>
<span class="sd">            pops the last state from the stack</span>
<span class="sd">            and sets all state variables to the </span>
<span class="sd">            corresponding values.</span>



<span class="sd">        Examples</span>
<span class="sd">        --------</span>


<span class="sd">        &gt;&gt;&gt; import convis</span>
<span class="sd">        &gt;&gt;&gt; import torch.nn.functional as F</span>
<span class="sd">        &gt;&gt;&gt; </span>
<span class="sd">        &gt;&gt;&gt; class Model(convis.Layer):</span>
<span class="sd">        &gt;&gt;&gt;     def __init__(self):</span>
<span class="sd">        &gt;&gt;&gt;         super(Model, self).__init__()</span>
<span class="sd">        &gt;&gt;&gt;         self.conv1 = convis.filters.Conv3d(1, (20,1,1))</span>
<span class="sd">        &gt;&gt;&gt;         self.conv2 = convis.filters.Conv3d(1, (1,10,10))</span>
<span class="sd">        &gt;&gt;&gt;     def forward(self, x):</span>
<span class="sd">        &gt;&gt;&gt;        x = F.relu(self.conv1(x))</span>
<span class="sd">        &gt;&gt;&gt;        return F.relu(self.conv2(x))</span>


<span class="sd">        .. _tab_completion_example:</span>

<span class="sd">        Selecting an :class:`~torch.optim.Optimizer` and using it with :meth:`~convis.base.Layer.optimize`:</span>

<span class="sd">        &gt;&gt;&gt; m = convis.models.LN()</span>
<span class="sd">        &gt;&gt;&gt; m.set_optimizer.&lt;then press tab&gt;</span>
<span class="sd">                            ASGD</span>
<span class="sd">                            Adadelta</span>
<span class="sd">                            Adagrad</span>
<span class="sd">                            Adam</span>
<span class="sd">                            ...</span>
<span class="sd">        &gt;&gt;&gt; m.set_optimizer.SGD(lr=0.01)</span>
<span class="sd">        &gt;&gt;&gt; m.optimize(input,output)</span>

<span class="sd">        The list of parameters as first argument can be omitted</span>
<span class="sd">        and will be filled with all parameters of the model by</span>
<span class="sd">        default. Other parameters are passed through to the optimizer</span>
<span class="sd">        eg. the learning rate :attr:`lr` in this example.</span>


<span class="sd">        .. _tab_completion_special_attributes_example:</span>

<span class="sd">        The special attributes `p`,`m`,`s` and `user_parameters`</span>
<span class="sd">        provide tab-completion for parameters, submodules and states:</span>

<span class="sd">        &gt;&gt;&gt; retina = convis.models.retina()</span>
<span class="sd">        &gt;&gt;&gt; print retina.p</span>
<span class="sd">        Parameters of the model (see also .user_parameters)</span>
<span class="sd">        Choices: gang_0_spikes, gang_1_spikes, gang_0_input, gang_1_input, bipolar, opl</span>
<span class="sd">        &gt;&gt;&gt; print retina.user_parameters</span>
<span class="sd">        Parameters of the model that can be set by the user.</span>
<span class="sd">        Choices: gang_0_spikes, gang_1_spikes, gang_0_input, gang_1_input, bipolar, opl</span>
<span class="sd">        &gt;&gt;&gt; print retina.p</span>
<span class="sd">        Modules of the model</span>
<span class="sd">        Choices: _self, gang_0_spikes, gang_1_spikes, gang_0_input, gang_1_input, bipolar, opl</span>
<span class="sd">        &gt;&gt;&gt; print retina.s</span>
<span class="sd">        Current state of the model</span>
<span class="sd">        Choices: gang_0_spikes, gang_1_spikes, gang_0_input, gang_1_input, bipolar, opl</span>

<span class="sd">        To find explore the parameters / modules / states,</span>
<span class="sd">        print the object to see the available choices or</span>
<span class="sd">        press tab:</span>

<span class="sd">        &gt;&gt;&gt; retina.p.&lt;tab complete&gt;</span>
<span class="sd">        &gt;&gt;&gt; retina.p.bi&lt;tab complete&gt;</span>
<span class="sd">        &gt;&gt;&gt; retina.p.bipolar.&lt;tab complete&gt;</span>
<span class="sd">        &gt;&gt;&gt; retina.p.bipolar.g_leak # the g_leak Parameter</span>

<span class="sd">        The hierarchical :class:`~convis.o.Ox` object provides </span>
<span class="sd">        a few special functions</span>

<span class="sd">        &gt;&gt;&gt; retina.p._all.bipolar_g_leak # lists everything in a flat list</span>
<span class="sd">        &gt;&gt;&gt; retina.p._search.leak.&lt;tab complete to search&gt;</span>
<span class="sd">        &gt;&gt;&gt; retina.p._search.leak.bipolar_g_leak # found one result</span>



<span class="sd">        See Also</span>
<span class="sd">        --------</span>

<span class="sd">        torch.nn.Module : torchs layer class</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_state</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_state</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_default_state</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_variables</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_named_variables</span><span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_debug</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_use_cuda</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_optimizer</span> <span class="o">=</span> <span class="n">_OptimizerSelector</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">register_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name</span><span class="p">,</span><span class="n">val</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_state</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_state</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_default_state</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<div class="viewcode-block" id="Layer.cuda"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.cuda">[docs]</a>    <span class="k">def</span> <span class="nf">cuda</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Moves the model to the GPU (optionally with number `device`).</span>
<span class="sd">            returns the model itself.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_use_cuda</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">m</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">:</span>
                <span class="n">m</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span></div>
<div class="viewcode-block" id="Layer.cpu"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.cpu">[docs]</a>    <span class="k">def</span> <span class="nf">cpu</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Moves the model to the CPU and returns the model itself.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_use_cuda</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">m</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">:</span>
                <span class="n">m</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span></div>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">new_args</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">prepare_input</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;dims&#39;</span><span class="p">,</span><span class="kc">None</span><span class="p">),</span> <span class="n">cuda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_cuda</span><span class="p">)</span>
            <span class="n">new_args</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">o0</span> <span class="o">=</span> <span class="n">o</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="o">*</span><span class="n">new_args</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;outputs&#39;</span><span class="p">):</span>
            <span class="n">o</span> <span class="o">=</span> <span class="n">Output</span><span class="p">([</span><span class="n">o</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">],</span> <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">]</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">o</span>
<div class="viewcode-block" id="Layer.run"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.run">[docs]</a>    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">the_input</span><span class="p">,</span><span class="n">dt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">t</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Runs the model either once, or multiple times to process chunks of size `dt`.</span>

<span class="sd">            Returns an `Output` object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">dt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_in_chunks</span><span class="p">(</span><span class="n">the_input</span><span class="p">,</span><span class="n">dt</span><span class="o">=</span><span class="n">dt</span><span class="p">,</span><span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Output</span><span class="p">(</span><span class="bp">self</span><span class="p">(</span><span class="n">the_input</span><span class="p">),</span><span class="n">keys</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">])</span></div>
    <span class="k">def</span> <span class="nf">_run_in_chunks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">the_input</span><span class="p">,</span><span class="n">dt</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">t</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="n">chunked_output</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">the_input</span><span class="p">))</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">the_input</span> <span class="o">=</span> <span class="n">the_input</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">,:,:,:]</span>
        <span class="k">while</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">shape</span><span class="p">(</span><span class="n">the_input</span><span class="p">)[</span><span class="mi">2</span><span class="p">]:</span>
            <span class="n">oo</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">the_input</span><span class="p">[:,:,</span><span class="n">t</span><span class="p">:(</span><span class="n">t</span><span class="o">+</span><span class="n">dt</span><span class="p">),:,:])</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">oo</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">Output</span><span class="p">:</span>
                <span class="n">oo</span> <span class="o">=</span> <span class="p">[</span><span class="n">oo</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">keys</span><span class="o">=</span><span class="n">oo</span><span class="o">.</span><span class="n">keys</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">o</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">oo</span><span class="p">):</span>
                <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunked_output</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span>
                    <span class="n">chunked_output</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
                <span class="n">chunked_output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">o</span><span class="p">)</span>
            <span class="n">t</span> <span class="o">+=</span> <span class="n">dt</span>
        <span class="n">outs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">co</span> <span class="ow">in</span> <span class="n">chunked_output</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">outs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">co</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="n">TIME_DIMENSION</span><span class="p">))</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">outs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">co</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">Output</span><span class="p">(</span><span class="n">outs</span><span class="p">,</span><span class="n">keys</span><span class="o">=</span><span class="n">keys</span><span class="p">)</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">p</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            A hierarchical, tab-completable list of all :class:`torch.nn.parameter.Parameter` of the model.</span>
<span class="sd">            If a parameters is reachable via `some_model.p.layer1.module1.parameter1`</span>
<span class="sd">            it will also be available directly as `some_model.layer1.module1.parameter1`.</span>
<span class="sd">            However for tab-completion, the later method provides *all* attributes</span>
<span class="sd">            of the model, not only parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">variables</span><span class="o">.</span><span class="n">create_Ox_from_torch_iterator_dicts</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(),</span>
            <span class="n">doc</span><span class="o">=</span><span class="s1">&#39;Parameters of the model (tab-completable, includes also parameters that should not be changed by the user. See also .user_parameters)&#39;</span><span class="p">)</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">user_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">variables</span><span class="o">.</span><span class="n">create_Ox_from_torch_iterator_dicts</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;set&#39;</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()),</span>
            <span class="n">doc</span><span class="o">=</span><span class="s1">&#39;Parameters of the model that can be set by the user via `.set()`. (tab-completable)&#39;</span><span class="p">)</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">m</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">variables</span><span class="o">.</span><span class="n">create_Ox_from_torch_iterator_dicts</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">named_modules</span><span class="p">(),</span>
            <span class="n">doc</span><span class="o">=</span><span class="s1">&#39;Modules of the model (tab-completable)&#39;</span><span class="p">)</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">s</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">variables</span><span class="o">.</span><span class="n">create_Ox_from_torch_iterator_dicts</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">(),</span>
            <span class="n">doc</span><span class="o">=</span><span class="s1">&#39;Current state of the model (tab-completable)&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>
            <span class="n">module</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_variables</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">var</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Variables stored in modules are graph leaves, and we don&#39;t</span>
                <span class="c1"># want to create copy nodes, so we have to unpack the data.</span>
                <span class="n">var</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">var</span><span class="o">.</span><span class="n">_grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">var</span><span class="o">.</span><span class="n">_grad</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">_grad</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">param</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Variables stored in modules are graph leaves, and we don&#39;t</span>
                <span class="c1"># want to create copy nodes, so we have to unpack the data.</span>
                <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">_grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">param</span><span class="o">.</span><span class="n">_grad</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">_grad</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">buf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">buf</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span>
    <span class="k">def</span> <span class="nf">__dir__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;_state&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_state</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="o">+</span> <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="o">+</span> <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_state</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_state</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">if</span> <span class="n">is_variable</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">==</span> <span class="n">Parameter</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_variables</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_named_variables</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__getattr__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_state</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_state</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__getattr__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
<div class="viewcode-block" id="Layer.parse_config"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.parse_config">[docs]</a>    <span class="k">def</span> <span class="nf">parse_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">config</span><span class="p">,</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span><span class="n">key</span><span class="o">=</span><span class="s1">&#39;retina_config_key&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Loads parameter values from a configuration (RetinaConfiguration or dict).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="s1">&#39;_variables&#39;</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">a</span><span class="o">.</span><span class="n">_variables</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="s1">&#39;retina_config_key&#39;</span><span class="p">):</span>
                        <span class="k">if</span> <span class="n">v</span><span class="o">.</span><span class="n">retina_config_key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="p">):</span>
                            <span class="k">continue</span>
                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="s1">&#39;set&#39;</span><span class="p">):</span>
                            <span class="k">try</span><span class="p">:</span>
                                <span class="n">v</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">prefix</span><span class="o">+</span><span class="n">v</span><span class="o">.</span><span class="n">retina_config_key</span><span class="p">))</span>
                            <span class="k">except</span><span class="p">:</span>
                                <span class="k">pass</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;has no set:&#39;</span><span class="p">,</span><span class="n">v</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">f</span><span class="p">)</span></div>
<div class="viewcode-block" id="Layer.compute_loss"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.compute_loss">[docs]</a>    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">outp</span><span class="p">,</span> <span class="n">loss_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="p">((</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">dt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Computes the loss of the model output in response to `inp`</span>
<span class="sd">            compared with the provided `outp` using `loss_fn`.</span>

<span class="sd">            Works like `optimize`, but does not use an actual optimizer.</span>

<span class="sd">            See Also</span>
<span class="sd">            --------</span>
<span class="sd">            optimize</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">class</span> <span class="nc">DummyOpt</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
            <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">x</span><span class="p">()</span>
            <span class="k">def</span> <span class="nf">zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
                <span class="k">pass</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">inp</span><span class="o">=</span><span class="n">inp</span><span class="p">,</span> <span class="n">outp</span><span class="o">=</span><span class="n">outp</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">DummyOpt</span><span class="p">(),</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="n">dt</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">)</span></div>
<div class="viewcode-block" id="Layer.optimize"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.optimize">[docs]</a>    <span class="k">def</span> <span class="nf">optimize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">outp</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">loss_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="p">((</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">dt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Runs an Optimizer to fit the models parameters such that the output</span>
<span class="sd">            of the model when presented :attr:`inp` approximates :attr:`outp`.</span>

<span class="sd">            To use this function, an :class:`torch.optim.Optimizer` has to be selected::</span>

<span class="sd">                &gt;&gt;&gt; model.set_optimizer(torch.optim.SGD(model.parameters(),lr=0.01))</span>
<span class="sd">                &gt;&gt;&gt; model.optimize(x,y, dt=100)</span>

<span class="sd">            or::</span>

<span class="sd">                &gt;&gt;&gt; model.set_optimizer.SGD(lr=0.01) # uses optimizers from torch.optim</span>
<span class="sd">                &gt;&gt;&gt; model.optimize(x,y, dt=100)</span>

<span class="sd">            It is important to specify a chunk length :attr:`dt`, if the complete input does not fit into memory.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Optimizer has to be set! Use .set_optimizer.&lt;tab&gt;&#39;</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span>
        <span class="k">def</span> <span class="nf">closure</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pop_state</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">push_state</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">closure</span><span class="o">.</span><span class="n">inp</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">closure</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">closure</span><span class="o">.</span><span class="n">outp</span><span class="p">,</span><span class="n">o</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">loss</span>
        <span class="n">inp</span> <span class="o">=</span> <span class="n">prepare_input</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;dims&#39;</span><span class="p">,</span><span class="kc">None</span><span class="p">),</span> <span class="n">cuda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_cuda</span><span class="p">)</span>
        <span class="n">outp</span> <span class="o">=</span> <span class="n">prepare_input</span><span class="p">(</span><span class="n">outp</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;dims&#39;</span><span class="p">,</span><span class="kc">None</span><span class="p">),</span> <span class="n">cuda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_cuda</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">push_state</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">dt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">steps</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">while</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">shape</span><span class="p">(</span><span class="n">inp</span><span class="p">)[</span><span class="n">TIME_DIMENSION</span><span class="p">]:</span>
                <span class="n">closure</span><span class="o">.</span><span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span><span class="p">[:,:,</span><span class="n">t</span><span class="p">:(</span><span class="n">t</span><span class="o">+</span><span class="n">dt</span><span class="p">),:,:]</span>
                <span class="n">closure</span><span class="o">.</span><span class="n">outp</span> <span class="o">=</span> <span class="n">outp</span><span class="p">[:,:,</span><span class="n">t</span><span class="p">:(</span><span class="n">t</span><span class="o">+</span><span class="n">dt</span><span class="p">),:,:]</span>
                <span class="n">t</span> <span class="o">+=</span> <span class="n">dt</span>
                <span class="n">closure</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>
                <span class="n">steps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">steps</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">closure</span><span class="o">.</span><span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span>
            <span class="n">closure</span><span class="o">.</span><span class="n">outp</span> <span class="o">=</span> <span class="n">outp</span>
            <span class="n">closure</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>
            <span class="k">return</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">)</span></div>
<div class="viewcode-block" id="Layer.get_parameters"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.get_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">get_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;returns an OrderedDict of all parameter values of the model</span>

<span class="sd">        The key of each entry is the respective path name</span>
<span class="sd">        (eg. &#39;submodule_submodule_variablename&#39;), the value</span>
<span class="sd">        is a numpy array.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        set_parameters</span>
<span class="sd">        push_parameters</span>
<span class="sd">        pop_parameters</span>
<span class="sd">        save_parameters</span>
<span class="sd">        load_parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">def</span> <span class="nf">_get</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="s1">&#39;get&#39;</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">v</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">v</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="s1">&#39;data&#39;</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">data</span><span class="p">,</span><span class="s1">&#39;numpy&#39;</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">v</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;what is v?&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">OrderedDict</span><span class="p">([(</span><span class="n">k</span><span class="p">,</span><span class="n">_get</span><span class="p">(</span><span class="n">v</span><span class="p">))</span> <span class="k">for</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">_all</span><span class="o">.</span><span class="n">__iteritems__</span><span class="p">()])</span></div>
<div class="viewcode-block" id="Layer.set_parameters"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.set_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">set_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">warn</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;sets parameter values from a dictionary.</span>

<span class="sd">        All parameters of the model will be loaded according</span>
<span class="sd">        to the respective path names (eg. &#39;submodule_submodule_variablename&#39;).</span>

<span class="sd">        .. note::</span>
<span class="sd">            It is important that you load the parameters to a</span>
<span class="sd">            model with the same structure and parameters of</span>
<span class="sd">            exactly the same name!</span>
<span class="sd">            Missing parameters (either in the file or the model) will be </span>
<span class="sd">            ignored silently.</span>
<span class="sd">            To enable warnings, set `Layer._debug` or the argument `warn` to `True`.</span>
<span class="sd">            If you changed the model structure, you can load the</span>
<span class="sd">            parameters with `np.load`, convert it into a dictionary</span>
<span class="sd">            and add or rename the parameters there.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        d (dict)</span>
<span class="sd">            dictionary with parameter values</span>
<span class="sd">        warn (bool)</span>
<span class="sd">            whether to warn of mismatching parameter names</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        get_parameters</span>
<span class="sd">        push_parameters</span>
<span class="sd">        pop_parameters</span>
<span class="sd">        save_parameters</span>
<span class="sd">        load_parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">matched</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">unmatched</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">_all</span><span class="o">.</span><span class="n">__iteritems__</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="s1">&#39;set&#39;</span><span class="p">):</span>
                    <span class="n">v</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
                <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="s1">&#39;data&#39;</span><span class="p">):</span>
                    <span class="n">v</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;what is </span><span class="si">%s</span><span class="s1">?&#39;</span><span class="o">%</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">v</span><span class="p">)))</span>
                <span class="n">matched</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_debug</span> <span class="ow">or</span> <span class="n">warn</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;No value for parameter </span><span class="se">\&#39;</span><span class="si">%s</span><span class="se">\&#39;</span><span class="s1"> in parameter values to load!&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
                    <span class="n">unmatched</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_debug</span> <span class="ow">or</span> <span class="n">warn</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">_all</span><span class="o">.</span><span class="n">__iterkeys__</span><span class="p">():</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;No parameter for parameter value </span><span class="se">\&#39;</span><span class="si">%s</span><span class="se">\&#39;</span><span class="s1">!&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
                    <span class="n">unmatched</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">unmatched</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Matched and loaded </span><span class="si">%i</span><span class="s1"> parameters. Failed to match </span><span class="si">%i</span><span class="s1"> parameter names!&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">matched</span><span class="p">,</span><span class="n">unmatched</span><span class="p">))</span></div>
<div class="viewcode-block" id="Layer.get_state"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.get_state">[docs]</a>    <span class="k">def</span> <span class="nf">get_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            collects the state and returns an</span>
<span class="sd">            OrderedDict </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">def</span> <span class="nf">rec</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
            <span class="n">o</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="s1">&#39;_state&#39;</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">s_name</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">_state</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">o</span><span class="p">[</span><span class="n">s_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">s_name</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">mod_name</span><span class="p">,</span><span class="n">mod</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()):</span>
                <span class="k">if</span> <span class="n">mod</span> <span class="ow">is</span> <span class="n">model</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">for</span> <span class="n">s_name</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="n">rec</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">o</span><span class="p">[</span><span class="n">mod_name</span><span class="o">+</span><span class="s1">&#39;.&#39;</span><span class="o">+</span><span class="n">s_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span>
            <span class="k">return</span> <span class="n">o</span>
        <span class="k">return</span> <span class="n">rec</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div>
<div class="viewcode-block" id="Layer.set_state"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.set_state">[docs]</a>    <span class="k">def</span> <span class="nf">set_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            collects the state and returns an</span>
<span class="sd">            OrderedDict </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">def</span> <span class="nf">rec</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sub_state_dict</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="s1">&#39;_state&#39;</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">s_name</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">_state</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="nb">setattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">s_name</span><span class="p">,</span> <span class="n">sub_state_dict</span><span class="p">[</span><span class="n">s_name</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">mod_name</span><span class="p">,</span><span class="n">mod</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()):</span>
                <span class="k">if</span> <span class="n">mod</span> <span class="ow">is</span> <span class="n">model</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="n">new_sub_state_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">s_name</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="n">sub_state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">s_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">mod_name</span><span class="o">+</span><span class="s1">&#39;.&#39;</span><span class="p">):</span>
                        <span class="n">new_sub_state_dict</span><span class="p">[</span><span class="n">s_name</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">mod_name</span><span class="o">+</span><span class="s1">&#39;.&#39;</span><span class="p">):]]</span> <span class="o">=</span> <span class="n">s</span>
                <span class="n">rec</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">new_sub_state_dict</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">rec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">)</span></div>
<div class="viewcode-block" id="Layer.clear_state"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.clear_state">[docs]</a>    <span class="k">def</span> <span class="nf">clear_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            resets the state to default values</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">def</span> <span class="nf">rec</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
            <span class="n">o</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="s1">&#39;_state&#39;</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">s_name</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">_state</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="s1">&#39;_default_state&#39;</span><span class="p">):</span>
                        <span class="n">old_val</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">_state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">s_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                        <span class="nb">setattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">s_name</span><span class="p">,</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">_default_state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">s_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)))</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">old_val</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">_state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">s_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                        <span class="nb">setattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">s_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                    <span class="n">o</span><span class="p">[</span><span class="n">s_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">old_val</span><span class="p">,</span><span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">s_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">mod_name</span><span class="p">,</span><span class="n">mod</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()):</span>
                <span class="k">if</span> <span class="n">mod</span> <span class="ow">is</span> <span class="n">model</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">for</span> <span class="n">s_name</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="n">rec</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">o</span><span class="p">[</span><span class="n">mod_name</span><span class="o">+</span><span class="s1">&#39;.&#39;</span><span class="o">+</span><span class="n">s_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span>
            <span class="k">return</span> <span class="n">o</span>
        <span class="k">return</span> <span class="n">rec</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div>
<div class="viewcode-block" id="Layer.save_parameters"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.save_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">save_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">filename</span><span class="p">,</span><span class="n">filetype</span><span class="o">=</span><span class="s1">&#39;npz&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;saves the model parameters to a file</span>

<span class="sd">        This function currently only supports the npz format.</span>
<span class="sd">        All parameters of the model will be saved as</span>
<span class="sd">        variables of the respective path names (eg. &#39;submodule_submodule_variablename&#39;).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        filename (str)</span>
<span class="sd">            name of the file to save to</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        load_parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">filetype</span> <span class="ow">is</span> <span class="s1">&#39;npz&#39;</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">savez</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Parameters can only be saved as npz at the moment.&#39;</span><span class="p">)</span></div>
<div class="viewcode-block" id="Layer.load_parameters"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.load_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">load_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">filename</span><span class="p">,</span><span class="n">filetype</span><span class="o">=</span><span class="s1">&#39;npz&#39;</span><span class="p">,</span><span class="n">warn</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;loads saved parameter values from a file.</span>

<span class="sd">        This function currently only supports the npz format.</span>
<span class="sd">        All parameters of the model will be loaded from npz</span>
<span class="sd">        variables of the respective path names (eg. &#39;submodule_submodule_variablename&#39;).</span>

<span class="sd">        .. note::</span>
<span class="sd">            It is important that you load the parameters to a</span>
<span class="sd">            model with the same structure and parameters of</span>
<span class="sd">            exactly the same name!</span>
<span class="sd">            Missing parameters (either in the file or the model) will be </span>
<span class="sd">            ignored silently. To enable warnings, set `Layer._debug` or</span>
<span class="sd">            the argument `warn` to `True`.</span>
<span class="sd">            If you changed the model structure, you can load the</span>
<span class="sd">            parameters with `np.load`, convert it into a dictionary</span>
<span class="sd">            and add or rename the parameters there.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        filename (str)</span>
<span class="sd">            name of the file to load from</span>
<span class="sd">        warn (bool)</span>
<span class="sd">            whether to warn of mismatching parameter names</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        save_parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">filetype</span> <span class="ow">is</span> <span class="s1">&#39;npz&#39;</span><span class="p">:</span>
            <span class="n">parameter_dict</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">parameter_dict</span><span class="p">,</span><span class="n">warn</span><span class="o">=</span><span class="n">warn</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Parameters can only be saved as npz at the moment.&#39;</span><span class="p">)</span></div>
<div class="viewcode-block" id="Layer.push_parameters"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.push_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">push_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            collects all parameter values and pushes their values onto a stack</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_parameter_stack&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_parameter_stack</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_parameter_stack</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">())</span></div>
<div class="viewcode-block" id="Layer.pop_parameters"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.pop_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">pop_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            retrieves the values of all parameters from a stack</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameter_stack</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">pars</span><span class="p">)</span></div>
<div class="viewcode-block" id="Layer.push_state"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.push_state">[docs]</a>    <span class="k">def</span> <span class="nf">push_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            collects all State variables and pushes their values onto a stack</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_state_stack&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_state_stack</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_state_stack</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_state</span><span class="p">())</span></div>
<div class="viewcode-block" id="Layer.pop_state"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.pop_state">[docs]</a>    <span class="k">def</span> <span class="nf">pop_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            retrieves the values of all State variables from a stack</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_state_stack&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;No state was pushed to the stack!&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_state_stack</span><span class="o">.</span><span class="n">pop</span><span class="p">())</span></div>
<div class="viewcode-block" id="Layer.push_optimizer"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.push_optimizer">[docs]</a>    <span class="k">def</span> <span class="nf">push_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            pushes the current optimizer onto a stack</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_optimizer_stack&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_stack</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_stack</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="p">)</span></div>
<div class="viewcode-block" id="Layer.pop_optimizer"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.pop_optimizer">[docs]</a>    <span class="k">def</span> <span class="nf">pop_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            retrieves the last optimizer from a stack</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">opt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_stack</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="n">opt</span></div>
<div class="viewcode-block" id="Layer.get_all"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.get_all">[docs]</a>    <span class="k">def</span> <span class="nf">get_all</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Returns the parameters, states and parameters in</span>
<span class="sd">            a dictionary.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="p">,</span>
            <span class="s1">&#39;state&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_state</span><span class="p">(),</span>
            <span class="s1">&#39;parameters&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span>
            <span class="p">}</span></div>
    <span class="k">def</span> <span class="nf">set_all</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="s1">&#39;optimizer&#39;</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span>
                <span class="s1">&#39;state&#39;</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span>
                <span class="s1">&#39;parameters&#39;</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;The provided dictionary needs to contain </span><span class="se">\&#39;</span><span class="s1">optimizer</span><span class="se">\&#39;</span><span class="s1">, </span><span class="se">\&#39;</span><span class="s1">state</span><span class="se">\&#39;</span><span class="s1"> and </span><span class="se">\&#39;</span><span class="s1">parameters</span><span class="se">\&#39;</span><span class="s1"> keys.&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;optimizer&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;state&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;parameters&#39;</span><span class="p">])</span>
<div class="viewcode-block" id="Layer.store_all"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.store_all">[docs]</a>    <span class="k">def</span> <span class="nf">store_all</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Stores parameters, states and parameter values</span>
<span class="sd">            in an internal dictionary.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_all_store&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_all_store</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_all_store</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_all</span><span class="p">()</span></div>
<div class="viewcode-block" id="Layer.retrieve_all"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.retrieve_all">[docs]</a>    <span class="k">def</span> <span class="nf">retrieve_all</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Retrieves parameters, states and parameter values</span>
<span class="sd">            from an internal dictionary.</span>

<span class="sd">            The entry is not deleted.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_all_store</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_all_store</span><span class="p">[</span><span class="n">name</span><span class="p">]</span></div>
<div class="viewcode-block" id="Layer.push_all"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.push_all">[docs]</a>    <span class="k">def</span> <span class="nf">push_all</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Pushes the parameters, states and parameters onto</span>
<span class="sd">            a shared stack.</span>

<span class="sd">            This stack does not interfere with the separate stacks</span>
<span class="sd">            of `push_parameters`, `push_optimizer` and `push_state`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_all_stack&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_all_stack</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_all_stack</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="p">,</span>
            <span class="s1">&#39;state&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_state</span><span class="p">(),</span>
            <span class="s1">&#39;parameters&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span>
            <span class="p">})</span></div>
<div class="viewcode-block" id="Layer.pop_all"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.pop_all">[docs]</a>    <span class="k">def</span> <span class="nf">pop_all</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Retrieves the parameters, states and parameters from</span>
<span class="sd">            a shared stack.</span>

<span class="sd">            This stack does not interfere with the separate stacks</span>
<span class="sd">            of `pop_parameters`, `pop_optimizer` and `pop_state`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">all_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_all_stack</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="n">all_dict</span><span class="p">[</span><span class="s1">&#39;optimizer&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">all_dict</span><span class="p">[</span><span class="s1">&#39;state&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">all_dict</span><span class="p">[</span><span class="s1">&#39;parameters&#39;</span><span class="p">])</span></div>
    <span class="k">def</span> <span class="nf">_repr_html_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">variable_describe</span><span class="o">.</span><span class="n">describe_layer_with_html</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<div class="viewcode-block" id="Layer.plot_impulse"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.plot_impulse">[docs]</a>    <span class="k">def</span> <span class="nf">plot_impulse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">shp</span><span class="o">=</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span><span class="n">dt</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Plots the response to a 1 bin impulse.</span>

<span class="sd">            The state of the model is preserved (pushed </span>
<span class="sd">            to the stack and poped later).</span>


<span class="sd">            Attributes</span>
<span class="sd">            ----------</span>

<span class="sd">            shp : tuple(t, x, y)</span>
<span class="sd">                the size of the stimulus. A larger stimulus</span>
<span class="sd">                will show a larger area of the impulse response</span>
<span class="sd">            dt : int</span>
<span class="sd">                length of chunks when computing the response</span>

<span class="sd">            Returns</span>
<span class="sd">            -------</span>
<span class="sd">            The output of the model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">.</span> <span class="k">import</span> <span class="n">plot_5d_time</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">push_state</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clear_state</span><span class="p">()</span>
        <span class="n">inp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shp</span><span class="p">)</span>
        <span class="n">inp</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="nb">int</span><span class="p">(</span><span class="n">shp</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span><span class="nb">int</span><span class="p">(</span><span class="n">shp</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span><span class="n">dt</span><span class="o">=</span><span class="n">dt</span><span class="p">)</span>
        <span class="n">plot_5d_time</span><span class="p">(</span><span class="n">o</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pop_state</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">o</span></div>
<div class="viewcode-block" id="Layer.plot_impulse_space"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.plot_impulse_space">[docs]</a>    <span class="k">def</span> <span class="nf">plot_impulse_space</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">shp</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">),</span><span class="n">dt</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Plots the response to a 1 bin impulse.</span>

<span class="sd">            The state of the model is preserved (pushed </span>
<span class="sd">            to the stack and poped later).</span>


<span class="sd">            Attributes</span>
<span class="sd">            ----------</span>

<span class="sd">            shp : tuple(t, x, y)</span>
<span class="sd">                the size of the stimulus. A larger stimulus</span>
<span class="sd">                will show a larger area of the impulse response</span>
<span class="sd">            dt : int</span>
<span class="sd">                length of chunks when computing the response</span>

<span class="sd">            Returns</span>
<span class="sd">            -------</span>
<span class="sd">            The output of the model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">.</span> <span class="k">import</span> <span class="n">plot_5d_matshow</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">push_state</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clear_state</span><span class="p">()</span>
        <span class="n">inp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shp</span><span class="p">)</span>
        <span class="n">inp</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="nb">int</span><span class="p">(</span><span class="n">shp</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span><span class="nb">int</span><span class="p">(</span><span class="n">shp</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span><span class="n">dt</span><span class="o">=</span><span class="n">dt</span><span class="p">)</span>
        <span class="n">plot_5d_matshow</span><span class="p">(</span><span class="n">o</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pop_state</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">o</span></div></div>

<span class="n">Model</span> <span class="o">=</span> <span class="n">Layer</span>

<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">OrderedDict</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="k">def</span> <span class="nf">get_next</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="n">l</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span> <span class="s1">&#39;get&#39;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">stream</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span> <span class="s1">&#39;__next__&#39;</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span> <span class="o">==</span> <span class="nb">list</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">stream</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">StopIteration</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">stream</span>

<span class="k">class</span> <span class="nc">_DummyModel</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">chunk_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">inps</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">([(</span><span class="n">k</span><span class="p">,</span><span class="n">get_next</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">l</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">())</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span>
        <span class="k">return</span> <span class="n">Output</span><span class="p">(</span><span class="n">inps</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span><span class="n">keys</span><span class="o">=</span><span class="n">inps</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        
<div class="viewcode-block" id="Runner"><a class="viewcode-back" href="../../docs.html#convis.base.Runner">[docs]</a><span class="k">class</span> <span class="nc">Runner</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Keeps track of the input and output of a model</span>
<span class="sd">        and can run or optimize it in a separate thread.</span>

<span class="sd">        :attr:`model` has to be a :class:`convis.base.Layer`</span>

<span class="sd">        :attr:`input` should be a :class:`convis.streams.Stream` that contains input data</span>
<span class="sd">        :attr:`output` should be a :class:`convis.streams.Stream` that accepts new data</span>
<span class="sd">        when using optimize, :attr:`goal` has to have the same length as input and the same behaviour at the end of the stream (repeating or stop)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">goal</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="nb">input</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">goal</span> <span class="o">=</span> <span class="n">goal</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">20</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">True</span>
<div class="viewcode-block" id="Runner.stop"><a class="viewcode-back" href="../../docs.html#convis.base.Runner.stop">[docs]</a>    <span class="k">def</span> <span class="nf">stop</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">True</span></div>
<div class="viewcode-block" id="Runner.start"><a class="viewcode-back" href="../../docs.html#convis.base.Runner.start">[docs]</a>    <span class="k">def</span> <span class="nf">start</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">import</span> <span class="nn">thread</span>
            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="kn">import</span> <span class="nn">_thread</span> <span class="k">as</span> <span class="nn">thread</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
            <span class="n">thread</span><span class="o">.</span><span class="n">start_new_thread</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thread</span><span class="p">,</span><span class="nb">tuple</span><span class="p">())</span></div>
    <span class="k">def</span> <span class="nf">thread</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">time</span><span class="o">,</span> <span class="nn">datetime</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
<div class="viewcode-block" id="Runner.run"><a class="viewcode-back" href="../../docs.html#convis.base.Runner.run">[docs]</a>    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">length</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">length</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">chunk_size</span><span class="p">):</span>
                <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">chunk_size</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">o</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">o</span> 
        <span class="k">else</span><span class="p">:</span>
            <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">get_next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input</span><span class="p">))</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">o</span><span class="p">,</span><span class="s1">&#39;keys&#39;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">o</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">o</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">o</span></div>
<div class="viewcode-block" id="Runner.optimize"><a class="viewcode-back" href="../../docs.html#convis.base.Runner.optimize">[docs]</a>    <span class="k">def</span> <span class="nf">optimize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">get_next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input</span><span class="p">),</span> <span class="n">get_next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">goal</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">o</span><span class="p">,</span><span class="s1">&#39;keys&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">o</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">o</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">o</span></div></div>
</pre></div>

           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Jacob Huth.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'0.5.2.2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>